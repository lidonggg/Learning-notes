## 缓存常见问题

- [缓存失效](#缓存失效)
- [缓存穿透](#缓存穿透)
- [缓存雪崩](#缓存雪崩)
- [数据不一致](#数据不一致)
- [数据并发竞争](#数据并发竞争)
- [Hot key](#Hot key)
- [Big key](#Big key)

from：<https://kaiwu.lagou.com/>

---

### 缓存失效

#### 问题描述

服务系统查询数据的时候，会首先查询缓存，如果缓存中不存在或者数据过期了，那么就会进一步去查询 DB，然后将查到的数据回写到缓存中并返回。由于缓存的性能要比一般的关系型数据库高很多，因此我们希望对于缓存能有更高的命中率。但是如果缓存中有大量的 key 同时失效的时候，很多缓存数据访问都会 miss，进而穿透到 DB，DB 的压力就会明显上升，由于 DB 的性能较差，这样请求的慢查率会明显上升。这就是缓存失效的问题。

#### 原因

导致缓存失效，特别是很多 key 一起失效的原因，跟写缓存的过期时间息息相关。在写缓存的时候，我们一般会给缓存设置一个过期时间，如果是批量写缓存，并且每个缓存都用了相同的过期时间，那么就会导致缓存的数据在相同的时间同时失效。

#### 解决方法

缓存失效是由于同一个时间点大量的 key 过期导致的，那么解决的办法显然就是让过期时间能够离散，我们可以在批量上传 key 的时候，给每个缓存设置一个随机的过期时间，让数据在未来的一段时间内慢慢失效，而不是瞬时全部失效。

除此之外，我们还可以在缓存即将过期的时候，去重新设置缓存数据，避免数据访问穿透到 DB。



### 缓存穿透

#### 问题描述

对于正常的数据，即时缓存中不存在，那么也会在 DB 中存在，然后就可以将 DB 中的数据回写到缓存中。但是如果有一些特殊的访客，查询一个不存在的 key，导致每次查询都会穿透到 DB，如果他在用这些 key 批量操作，那么就会导致所有的请求都访问到 DB，从而大大增大数据库的压力，影响正常的业务请求。

#### 原因

缓存穿透存在的原因，就是我们在系统设计时，更多考虑的是正常访问路径，对特殊访问路径、异常访问路径考虑相对欠缺。

缓存访问设计的正常路径，是先访问 cache，cache miss 后查 DB，DB 查询到结果后，回种缓存返回。这对于正常的 key 访问是没有问题的，但是如果用户访问的是一个不存在的 key，查 DB 返回空（即一个 NULL），那就不会把这个空写回cache。那以后不管查询多少次这个不存在的 key，都会 cache miss，都会查询 DB。整个系统就会退化成一个“前端+DB“的系统，由于 DB 的吞吐只在 cache 的 1%~2% 以下，如果有特殊访客，大量访问这些不存在的 key，就会导致系统的性能严重退化，影响正常用户的访问。

#### 解决方法

这里给出两种解决方法：

- 第一种方案就是，查询这些不存在的数据时，第一次查 DB，虽然没查到结果返回 NULL，仍然记录这个 key 到缓存，只是这个 key 对应的 value 是一个特殊设置的值。但是如果特殊访客持续访问大量的不存在的 key，这些 key 即便只存一个简单的默认值，也会占用大量的缓存空间，导致正常 key 的命中率下降。所以进一步的改进措施是对这些不存在的 key 只存较短的时间，让它们尽快过期；或者将这些不存在的 key 存在一个独立的公共缓存，从缓存查找时，先查正常的缓存组件，如果 miss，则查一下公共的非法 key 的缓存，如果后者命中，直接返回，否则穿透 DB，如果查出来是空，则回种到非法 key 缓存，否则回种到正常缓存。

- 第二种方案是，构建一个 BloomFilter 缓存过滤器，记录全量数据，这样访问数据时，可以直接通过 BloomFilter 判断这个 key 是否存在，如果不存在直接返回即可，根本无需查缓存和 DB。但是如果 BloomFilter 要缓存全量的 key，这就要求全量的 key 数量不大，10 亿条数据以内最佳，因为 10 亿条数据大概要占用 1.2GB 的内存。除此之外，我们也可以用 BloomFilter 只缓存非法 key，每次发现一个 key 是不存在的非法 key，就记录到 BloomFilter 中，这种记录方案，会导致 BloomFilter 存储的 key 持续高速增长，为了避免记录 key 太多而导致误判率增大，需要定期清零处理。

  ​

###缓存雪崩

#### 问题描述

缓存雪崩是指部分缓存节点不可用，导致整个缓存体系甚至甚至服务系统不可用的情况。

#### 原因

当一些缓存节点不可用的时候，一般会有两种情况：

- 一种是这些节点上的数据不重新转移(rehash)到其他节点上面，此时如果节点是单副本的，那么对于这些节点上的 key 的访问，都会穿透到 DB 中，如果超过了 DB 的负载能力，就极有可能导致整个系统崩溃。
- 还有一种情况是不可用节点上的数据会 rehash (一致性 hash 算法等)到其他节点上面，这个时候如果失效节点过多，需要 rehash 的数据量过大，在遇到请求洪峰的时候，极有可能导致幸存的缓存节点也因为负载压力过大而产生异常 crash，而这些新失效的节点数据也会 rehash 到其他活着的节点上，这个时候就会产生蝴蝶效应，进入了一个死循环，最终极有可能导致整个缓存集群整体宕机，严重影响服务调用。

#### 解决方法

这里给出三种解决方案：

- 对业务 DB 的访问增加读写开关，当发现 DB 请求变慢、阻塞，慢请求超过阀值时，就会关闭读开关，部分或所有读 DB 的请求进行 failfast 立即返回，待 DB 恢复后再打开读开关。
- 对缓存增加多个副本，缓存异常或请求 miss 后，再读取其他缓存副本，而且多个缓存副本尽量部署在不同机架，从而确保在任何情况下，缓存系统都会正常对外提供服务。
- 对缓存体系进行实时监控，当请求访问的慢速比超过阀值时，及时报警，通过机器替换、服务替换进行及时恢复；也可以通过各种自动故障转移策略，自动关闭异常接口、停止边缘服务、停止部分非核心功能措施，确保在极端场景下，核心功能的正常运行。

这三种方案的侧重点各不相同，方案一侧重于对 DB 的过载保护，方案二侧重于缓存节点的容错，方案三则侧重于对整个架构的异常监控和处理等，因此我们可以考虑同时采用，这也是一般大厂的解决方案。



### 数据不一致

#### 问题描述

因为有了缓存的存在，同一份数据就会有两个数据源，这个时候就有可能存在两个数据源上的数据不一致的情况。

#### 原因

不一致的问题大多跟缓存更新异常有关，比如以下一些情况：

- 更新 DB 后，写缓存失败，从而导致缓存中存的是老数据。
- 如果系统采用一致性 Hash 分布，同时采用 rehash 自动漂移策略，在节点多次上下线之后，也会产生脏数据。
- 缓存有多个副本时，更新某个副本失败，也会导致这个副本的数据是老数据。

#### 解决方法

- cache 更新失败后，可以进行重试，如果重试失败，则将失败的 key 写入队列服务，待缓存访问恢复后，将这些 key 从缓存删除。这些 key 在再次被查询时，重新从 DB 加载，从而保证数据的一致性。
- 缓存时间适当调短，让缓存数据及早过期后，然后从 DB 重新加载，确保数据的最终一致性。
- 不采用 rehash 漂移策略，而采用缓存分层策略，尽量避免脏数据产生。



### 数据并发竞争

#### 问题描述

数据并发竞争，是指在高并发访问场景，一旦缓存访问没有找到数据，大量请求就会并发查询 DB，导致 DB 压力大增的现象。

#### 原因

数据并发竞争，主要是由于多个进程/线程中，有大量并发请求获取相同的数据，而这个数据 key 因为正好过期、被剔除等各种原因在缓存中不存在，这些进程/线程之间没有任何协调，然后一起并发查询 DB，请求那个相同的 key，最终导致 DB 压力大增。

#### 解决方法

- 使用全局锁，即当缓存请求 miss 后，先尝试加全局锁，只有加全局锁成功的线程，才可以到 DB 去加载据。其他进程/线程在读取缓存数据 miss 时，如果发现这个 key 有全局锁，就进行等待，待之前的线程将数据从 DB 回种到缓存后，再从缓存获取。
- 对缓存数据保持多个备份，即便其中一个备份中的数据过期或被剔除了，还可以访问其他备份，从而减少数据并发竞争的情况。



### Hot key

#### 问题描述

对于大多数互联网系统，数据是分冷热的。在突发事件发生时，大量用户同时去访问同一个 (Hot) key，这个 key 所在的缓存节点就很容易出现过载和卡顿现象，甚至会被 Crash。

#### 原因

Hot key 引发缓存系统异常，主要是因为突发热门事件发生时，超大量的请求访问热点事件对应的 key。数十万的访问请求同一个 key，流量集中打在一个缓存节点机器，这个缓存机器很容易被打到物理网卡、带宽、CPU 的极限，从而导致缓存访问变慢、卡顿。

#### 解决方法

要解决这种极热 key 的问题，首先要找出这些 Hot key 来。对于重要节假日、线上促销活动、集中推送这些提前已知的事情，可以提前评估出可能的热 key 来。而对于突发事件，无法提前评估，可以通过 Spark，对应流任务进行实时分析，及时发现新发布的热点 key。而对于之前已发出的事情，逐步发酵成为热 key 的，则可以通 Hadoop 对批处理任务离线计算，找出最近历史数据中的高频热 key。

找到热 key 后：

- 可以将这些 hot key 进行分散处理，比如一个 hot key 名字叫 hotkey，可以被分散为 hotkey#1、hotkey#2、hotkey#3，……hotkey#n，这 n 个 key 分散存在多个缓存节点，然后 client 端请求时，随机访问其中某个后缀的 hotkey，这样就可以把热 key 的请求打散，避免一个缓存节点过载。
- 其次，也可以 key 的名字不变，对缓存提前进行多副本+多级结合的缓存架构设计。
- 再次，如果 hot key 较多，还可以通过监控体系对缓存的 SLA 实时监控，通过快速扩容来减少 hot key 的冲击。
- 最后，业务端还可以使用本地缓存，将这些 hot key 记录在本地缓存，来减少对远程缓存的冲击。



### Big key

#### 问题描述

Big key，是指在缓存访问时，部分 Key 的 Value 过大，读写、加载易超时的现象。

#### 原因

造成这些大 key 慢查询的原因很多：

- 如果这些大 key 占总体数据的比例很小，存 Mc (Memcached)，对应的 slab 较少，导致很容易被频繁剔除，DB 反复加载，从而导致查询较慢。
- 如果业务中这种大 key 很多，而这种 key 被大量访问，缓存组件的网卡、带宽很容易被打满，也会导致较多的大 key 慢查询。
- 另外，如果大 key 缓存的字段较多，每个字段的变更都会引发对这个缓存数据的变更，同时这些 key 也会被频繁地读取，读写相互影响，也会导致慢查现象。
- 最后，大 key 一旦被缓存淘汰，DB 加载可能需要花费很多时间，这也会导致大 key 查询慢的问题。

#### 解决方法

- 第一种方案，如果数据存在 Mc 中，可以设计一个缓存阀值，当 value 的长度超过阀值，则对内容启用压缩，让 KV 尽量保持小的 size，其次评估大 key 所占的比例，在 Mc 启动之初，就立即预写足够数据的大 key，让 Mc 预先分配足够多的 trunk size 较大的 slab。确保后面系统运行时，大 key 有足够的空间来进行缓存。       
- 第二种方案，如果数据存在 Redis 中，比如业务数据存 set 格式，大 key 对应的 set 结构有几千几万个元素，这种写入 Redis 时会消耗很长的时间，导致 Redis 卡顿。此时，可以扩展新的数据结构，同时让 client 在这些大 key 写缓存之前，进行序列化构建，然后通过 restore 一次性写入。
- 第三种方案时，如下图所示，将大 key 分拆为多个 key，尽量减少大 key 的存在。同时由于大 key 一旦穿透到 DB，加载耗时很大，所以可以对这些大 key 进行特殊照顾，比如设置较长的过期时间，比如缓存内部在淘汰 key 时，同等条件下，尽量不淘汰这些大 key。



### 总结

对于互联网系统，由于实际业务场景复杂，数据量、访问量巨大，需要提前规避缓存使用中的各种坑。我们可以通过提前熟悉 Cache 的经典问题，提前构建防御措施， 避免大量 key 同时失效，避免不存在 key 访问的穿透，减少大 key、热 key 的缓存失效，对热 key 进行分流。你可以采取一系列措施，让访问尽量命中缓存，同时保持数据的一致性。另外，你还可以结合业务模型，提前规划 cache 系统的 SLA，如 QPS、响应分布、平均耗时等，实施监控，以方便运维及时应对。在遇到部分节点异常，或者遇到突发流量、极端事件时，也能通过分池分层策略、key 分拆等策略，避免故障发生。